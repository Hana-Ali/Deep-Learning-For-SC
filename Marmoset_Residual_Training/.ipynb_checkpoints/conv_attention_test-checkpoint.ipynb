{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T13:11:27.775985Z",
     "iopub.status.busy": "2023-08-03T13:11:27.775142Z",
     "iopub.status.idle": "2023-08-03T13:11:28.333699Z",
     "shell.execute_reply": "2023-08-03T13:11:28.333077Z",
     "shell.execute_reply.started": "2023-08-03T13:11:27.775950Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import CNN_Attention\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T13:11:28.804724Z",
     "iopub.status.busy": "2023-08-03T13:11:28.803881Z",
     "iopub.status.idle": "2023-08-03T13:11:35.082992Z",
     "shell.execute_reply": "2023-08-03T13:11:35.082394Z",
     "shell.execute_reply.started": "2023-08-03T13:11:28.804689Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "# Empty cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 2\n",
    "# # Define the previous predictions\n",
    "# previous_prediction_1 = torch.randn((batch_size, 1, 3))\n",
    "# previous_prediction_2 = torch.randn((batch_size, 1, 3))\n",
    "# # Concatenate the previous predictions together along the rows\n",
    "# previous_predictions = torch.cat((previous_prediction_1, previous_prediction_2), dim=2).to(device)\n",
    "# # Define the input shape\n",
    "input_shape = (batch_size, 45, 15, 15, 15)\n",
    "# inputs = torch.randn(input_shape).to(device)\n",
    "\n",
    "# Define the model\n",
    "model = CNN_Attention(in_channels=45, num_rnn_layers=2, num_rnn_hidden_neurons=128, cube_size=input_shape[-1], num_nodes=1, num_coordinates=3, combination=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T13:11:35.084432Z",
     "iopub.status.busy": "2023-08-03T13:11:35.084010Z",
     "iopub.status.idle": "2023-08-03T13:11:35.087864Z",
     "shell.execute_reply": "2023-08-03T13:11:35.087291Z",
     "shell.execute_reply.started": "2023-08-03T13:11:35.084396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    2969 MB |    2969 MB |    2969 MB |       0 B  |\n",
      "|       from large pool |    2968 MB |    2968 MB |    2968 MB |       0 B  |\n",
      "|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    2969 MB |    2969 MB |    2969 MB |       0 B  |\n",
      "|       from large pool |    2968 MB |    2968 MB |    2968 MB |       0 B  |\n",
      "|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    2970 MB |    2970 MB |    2970 MB |       0 B  |\n",
      "|       from large pool |    2968 MB |    2968 MB |    2968 MB |       0 B  |\n",
      "|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  264192 B  |    2044 KB |    2044 KB |    1786 KB |\n",
      "|       from large pool |       0 B  |       0 KB |       0 KB |       0 KB |\n",
      "|       from small pool |  264192 B  |    2044 KB |    2044 KB |    1786 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      48    |      48    |      48    |       0    |\n",
      "|       from large pool |       2    |       2    |       2    |       0    |\n",
      "|       from small pool |      46    |      46    |      46    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      48    |      48    |      48    |       0    |\n",
      "|       from large pool |       2    |       2    |       2    |       0    |\n",
      "|       from small pool |      46    |      46    |      46    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       3    |       3    |       3    |       0    |\n",
      "|       from large pool |       2    |       2    |       2    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T12:14:38.663088Z",
     "iopub.status.busy": "2023-08-02T12:14:38.662477Z",
     "iopub.status.idle": "2023-08-02T12:14:39.010824Z",
     "shell.execute_reply": "2023-08-02T12:14:39.010130Z",
     "shell.execute_reply.started": "2023-08-02T12:14:38.663066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of first_block torch.Size([2, 45, 15, 15, 15])\n",
      "Shape of second_block torch.Size([2, 45, 15, 15, 15])\n",
      "Shape of third_block torch.Size([2, 45, 15, 15, 15])\n",
      "Shape of fourth_block torch.Size([2, 45, 15, 15, 15])\n",
      "Shape of fifth_block torch.Size([2, 45, 15, 15, 15])\n",
      "Shape of sixth_block torch.Size([2, 45, 15, 15, 15])\n",
      "Shape of previous_predictions_mlp_output torch.Size([2, 32])\n",
      "Shape of previous_predictions torch.Size([2, 32])\n",
      "Shape of cnn_attention_output torch.Size([2, 45, 15, 15, 15])\n",
      "Shape of flattened_input torch.Size([2, 151875])\n",
      "Shape of final_mlp torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "outputs = model(inputs, previous_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.cpu().detach().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

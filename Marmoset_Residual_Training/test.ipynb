{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T20:34:22.923039Z",
     "iopub.status.busy": "2023-07-25T20:34:22.922728Z",
     "iopub.status.idle": "2023-07-25T20:34:23.005699Z",
     "shell.execute_reply": "2023-07-25T20:34:23.005107Z",
     "shell.execute_reply.started": "2023-07-25T20:34:22.922975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 178, 115)\n",
      "(3,)\n",
      "torch.Size([1, 1, 1, 1, 3])\n",
      "torch.Size([1, 1, 128, 178, 115])\n",
      "torch.Size([1, 1, 1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Path to an image\n",
    "path = \"/notebooks/model_data_w_resize/dMRI_b0/A10-R01_0028-TT21/DWI_concatenated_b0_resized.nii.gz\"\n",
    "injection_center = \"/notebooks/model_data_w_resize/injection_centers/A10-R01_0028-TT21/inj_center.csv\"\n",
    "\n",
    "# Load the image\n",
    "image = nib.load(path)\n",
    "data = image.get_fdata()\n",
    "print(data.shape)\n",
    "\n",
    "# Load the injection center\n",
    "injection_center = np.loadtxt(injection_center, delimiter=\",\")\n",
    "print(injection_center.shape)\n",
    "\n",
    "# Turn the data into a torch tensor\n",
    "injection_center = torch.from_numpy(injection_center).unsqueeze(0).unsqueeze(0).unsqueeze(0).unsqueeze(0).float()\n",
    "data_torch = torch.from_numpy(data).unsqueeze(0).unsqueeze(0).float()\n",
    "image_coordinates = torch.from_numpy(np.array([3, 3, 3])).unsqueeze(0).unsqueeze(0).unsqueeze(0).unsqueeze(0).float()\n",
    "print(injection_center.shape)\n",
    "print(data_torch.shape)\n",
    "print(image_coordinates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T20:34:23.349044Z",
     "iopub.status.busy": "2023-07-25T20:34:23.348514Z",
     "iopub.status.idle": "2023-07-25T20:34:23.649312Z",
     "shell.execute_reply": "2023-07-25T20:34:23.648304Z",
     "shell.execute_reply.started": "2023-07-25T20:34:23.349016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "from training import *\n",
    "\n",
    "b0_cube = grab_cube_around_voxel(image=data_torch, voxel_coordinates=[5, 5, 5], kernel_size=16)\n",
    "b0_cube = torch.from_numpy(b0_cube).float()\n",
    "\n",
    "print(b0_cube.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T20:34:26.809159Z",
     "iopub.status.busy": "2023-07-25T20:34:26.808539Z",
     "iopub.status.idle": "2023-07-25T20:34:26.824230Z",
     "shell.execute_reply": "2023-07-25T20:34:26.823590Z",
     "shell.execute_reply.started": "2023-07-25T20:34:26.809131Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResnetEncoder(nn.Module):\n",
    "    \n",
    "    # Constructor \n",
    "    def __init__(self, input_nc, output_nc=1, ngf=64, n_blocks=6, norm_layer=nn.BatchNorm3d, use_dropout=False, \n",
    "                 padding_type='reflect', voxel_wise=False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            input_nc (int) -- the number of channels in input images\n",
    "            output_nc (int) -- the number of channels in output images\n",
    "            ngf (int) -- the number of filters in the last conv layer\n",
    "            n_blocks (int) -- the number of residual blocks\n",
    "            norm_layer -- normalization layer\n",
    "            use_dropout (bool) -- if use dropout layers\n",
    "            padding_type (str) -- the name of padding layer in conv layers: reflect | replicate | zero\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize parent class\n",
    "        super(ResnetEncoder, self).__init__()\n",
    "\n",
    "        # Initialize the self attributes\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.ngf = ngf\n",
    "        self.n_blocks = n_blocks\n",
    "        self.norm_layer = self.get_norm_layer(norm_layer)\n",
    "        self.use_dropout = use_dropout\n",
    "        self.padding_type = padding_type\n",
    "        self.voxel_wise = voxel_wise\n",
    "\n",
    "        # Whatever this is\n",
    "        if type(norm_layer) == partial:\n",
    "            self.use_bias = norm_layer.func == nn.InstanceNorm3d\n",
    "        else:\n",
    "            self.use_bias = norm_layer == nn.InstanceNorm3d\n",
    "\n",
    "        # Define the models\n",
    "        self.img_model = self.define_img_model()\n",
    "        self.non_img_model = self.define_non_img_model()\n",
    "        self.joint_model = self.define_joint_model()\n",
    "\n",
    "    # Define the model\n",
    "    def define_img_model(self):\n",
    "        \"\"\"\n",
    "        Define the model architecture\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize the model and padding size\n",
    "        model = []\n",
    "        padding_size = 3\n",
    "        \n",
    "        # Define the stride, based on voxel_wise\n",
    "        if self.voxel_wise:\n",
    "            stride = 2\n",
    "        else:\n",
    "            stride = 1\n",
    "\n",
    "        # Define the padding layer\n",
    "        if self.padding_type == 'reflect':\n",
    "            padding_layer = nn.ReflectionPad3d(padding_size)\n",
    "        elif self.padding_type == 'replicate':\n",
    "            padding_layer = nn.ReplicationPad3d(padding_size)\n",
    "        elif self.padding_type == 'zero':\n",
    "            padding_layer = nn.ZeroPad3d(padding_size)\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % self.padding_type)\n",
    "        \n",
    "        # 1. Add the first block\n",
    "        model.extend([padding_layer, \n",
    "                      nn.Conv3d(self.input_nc, self.ngf, kernel_size=7, padding=0, bias=self.use_bias), \n",
    "                      self.norm_layer(self.ngf), nn.ReLU(True)])\n",
    "        \n",
    "        # 2. Add one convolution\n",
    "        number_downsampling = 2\n",
    "        self.number_downsampling = number_downsampling\n",
    "        mult = 2**number_downsampling\n",
    "        model += [nn.Conv3d(self.ngf, self.ngf * mult, kernel_size=3,\n",
    "                    stride=1, padding=1, bias=False),\n",
    "                        self.norm_layer(self.ngf * mult), nn.ReLU(True)]\n",
    "\n",
    "        # 3. Add the residual blocks\n",
    "        for i in range(self.n_blocks):\n",
    "            model += [ResnetBlock(self.ngf * mult, padding_type=self.padding_type, \n",
    "                                  norm_layer=self.norm_layer, use_dropout=self.use_dropout, \n",
    "                                  use_bias=self.use_bias)]\n",
    "            \n",
    "        # 4. Add more downsampling blocks\n",
    "        # Cube output: stride 1 | Voxel output: stride 2\n",
    "        for i in range(number_downsampling):\n",
    "            mult = 2**(number_downsampling - i)\n",
    "            model += [nn.Conv3d(self.ngf * mult, int(self.ngf * mult / 2), \n",
    "                                kernel_size=3, stride=stride, padding=1, bias=self.use_bias), \n",
    "                          self.norm_layer(int(self.ngf * mult / 2)), \n",
    "                          nn.ReLU(True)]\n",
    "            \n",
    "        # 5. Add another convolutional block for vibes\n",
    "        # Cube output: stride 1 | Voxel output: stride 2\n",
    "        model += [nn.Conv3d(int(self.ngf * mult / 2), int(self.ngf * mult / 4),\n",
    "                            kernel_size=3, stride=stride, padding=1, bias=self.use_bias),\n",
    "                             self.norm_layer(int(self.ngf * mult / 4)), nn.ReLU(True)]\n",
    "            \n",
    "        # 4. Add the last block to make the number of channels as the output_nc and reduce spatial space\n",
    "        model += [nn.Conv3d(int(self.ngf * mult / 4), self.output_nc, kernel_size=3, stride=2, padding=1, bias=self.use_bias)]\n",
    "        \n",
    "        # Cube output: No Adaptive layer | Voxel output: Adaptive layer\n",
    "        if self.voxel_wise:\n",
    "            model += [nn.AdaptiveAvgPool3d((1, 1, 1))]\n",
    "        \n",
    "        # Return the model\n",
    "        return nn.Sequential(*model)\n",
    "    \n",
    "    # Define the processing for the non-image inputs\n",
    "    def define_non_img_model(self):\n",
    "        \n",
    "        # Stores the model\n",
    "        model = []\n",
    "        \n",
    "        # Add convolutions for the injection centers and image coordinates - expected to have self.output_nc channels\n",
    "        for i in range(self.number_downsampling):\n",
    "            model += [nn.Conv3d(self.output_nc, self.output_nc, kernel_size=3, stride=1, padding=1, bias=self.use_bias),\n",
    "                      self.norm_layer(self.output_nc), \n",
    "                          nn.ReLU(True)]\n",
    "            \n",
    "        # Return the model\n",
    "        return nn.Sequential(*model)\n",
    "            \n",
    "    # Define joint processing for everything\n",
    "    def define_joint_model(self):\n",
    "        \n",
    "        # Stores the model\n",
    "        model = []\n",
    "        \n",
    "        # Define the factor we multiply by, based on voxel_wise\n",
    "        if self.voxel_wise:\n",
    "            factor = 1\n",
    "        else:\n",
    "            factor = 3\n",
    "        \n",
    "        # Add final convolutions for image and non-image data\n",
    "        # Cube output: self.output_nc * 3 channels | Voxel output: self.output_nc channels\n",
    "        for i in range(self.number_downsampling):\n",
    "            model += [nn.Conv3d(self.output_nc * factor, self.output_nc * factor, kernel_size=3, stride=1, padding=1, \n",
    "                                bias=self.use_bias),\n",
    "                      self.norm_layer(self.output_nc), \n",
    "                          nn.ReLU(True)]\n",
    "            \n",
    "        # Final convolution to make the number of channels 1\n",
    "        # Cube output: self.output_nc * 3 channels | Voxel output: self.output_nc channels\n",
    "        model += [nn.Conv3d(self.output_nc * factor, self.output_nc, kernel_size=3, stride=1, padding=1, bias=self.use_bias)]\n",
    "        \n",
    "        # Cube output: No Adaptive layer | Voxel output: Adaptive layer\n",
    "        if self.voxel_wise:\n",
    "            model += [nn.AdaptiveAvgPool3d((1, 1, 1))]\n",
    "            \n",
    "        # Return the model\n",
    "        return nn.Sequential(*model)\n",
    "    \n",
    "    # Get the normalization layer\n",
    "    def get_norm_layer(self, norm_layer):\n",
    "\n",
    "        # If the norm layer is batch norm, we return it\n",
    "        if \"batch\" in norm_layer.lower():\n",
    "            return nn.BatchNorm3d\n",
    "        elif \"instance\" in norm_layer.lower():\n",
    "            return nn.InstanceNorm3d\n",
    "        else:\n",
    "            raise NotImplementedError('normalization layer [%s] is not found' % norm_layer)\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, input_x, injection_center, image_coordinates):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define the dimension we concatenate along, depending on voxel wise\n",
    "        if self.voxel_wise:\n",
    "            dim = 4\n",
    "        else:\n",
    "            dim = 1\n",
    "\n",
    "        # Do all the convolutions on the cube first\n",
    "        for layer in self.img_model:\n",
    "            input_x = layer(input_x)\n",
    "            print(input_x.shape)\n",
    "            \n",
    "        # Do the convolutional layers for the injection center\n",
    "        injection_center = self.non_img_model(injection_center)\n",
    "        \n",
    "        # Do the convolutional layers for the image coordinates\n",
    "        image_coordinates = self.non_img_model(image_coordinates)\n",
    "        \n",
    "        # Concatenate the data along the number of channels\n",
    "        # Cube output: Dimension 1 | Voxel output: Dimension 4\n",
    "        input_x = torch.cat((input_x, injection_center), dim=dim)\n",
    "        input_x = torch.cat((input_x, image_coordinates), dim=dim)\n",
    "        \n",
    "        # Do the joint processing\n",
    "        joint_data = self.joint_model(input_x)\n",
    "                        \n",
    "        # Return the model\n",
    "        return joint_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T20:34:31.387461Z",
     "iopub.status.busy": "2023-07-25T20:34:31.386736Z",
     "iopub.status.idle": "2023-07-25T20:34:34.525918Z",
     "shell.execute_reply": "2023-07-25T20:34:34.525237Z",
     "shell.execute_reply.started": "2023-07-25T20:34:31.387433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 38, 38, 38])\n",
      "torch.Size([1, 64, 32, 32, 32])\n",
      "torch.Size([1, 64, 32, 32, 32])\n",
      "torch.Size([1, 64, 32, 32, 32])\n",
      "torch.Size([1, 256, 32, 32, 32])\n",
      "torch.Size([1, 256, 32, 32, 32])\n",
      "torch.Size([1, 256, 32, 32, 32])\n",
      "torch.Size([1, 256, 32, 32, 32])\n",
      "torch.Size([1, 256, 32, 32, 32])\n",
      "torch.Size([1, 256, 32, 32, 32])\n",
      "torch.Size([1, 128, 16, 16, 16])\n",
      "torch.Size([1, 128, 16, 16, 16])\n",
      "torch.Size([1, 128, 16, 16, 16])\n",
      "torch.Size([1, 64, 8, 8, 8])\n",
      "torch.Size([1, 64, 8, 8, 8])\n",
      "torch.Size([1, 64, 8, 8, 8])\n",
      "torch.Size([1, 32, 4, 4, 4])\n",
      "torch.Size([1, 32, 4, 4, 4])\n",
      "torch.Size([1, 32, 4, 4, 4])\n",
      "torch.Size([1, 1, 2, 2, 2])\n",
      "torch.Size([1, 1, 1, 1, 1])\n",
      "output shape is:  torch.Size([1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "model = ResnetEncoder(input_nc=1, ngf=64, n_blocks=3, norm_layer=nn.BatchNorm3d, \n",
    "                      padding_type='reflect', voxel_wise=True)\n",
    "output = model(b0_cube, injection_center, image_coordinates)\n",
    "\n",
    "print(\"output shape is: \", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeeze the output\n",
    "output = output.squeeze(0).squeeze(0).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 356, 230)\n",
      "(1,)\n",
      "[-120.82841]\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "def glob_files(PATH_NAME, file_format):\n",
    "    INPUT_FILES = []\n",
    "    for file in glob.glob(os.path.join(PATH_NAME, os.path.join(\"**\", \"*.{}\".format(file_format))), recursive=True):\n",
    "        INPUT_FILES.append(file)\n",
    "    return INPUT_FILES\n",
    "\n",
    "nii_gz_files = glob_files(\"/notebooks/model_data_w_resize\", \"nii.gz\")\n",
    "b0_images = [file for file in nii_gz_files if \"b0\" in file and \"resized\" not in file]\n",
    "print(len(b0_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 356, 256)\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "reader = sitk.ImageFileReader()\n",
    "reader.SetFileName(b0_images[0])\n",
    "image = reader.Execute()\n",
    "\n",
    "normalizeFilter = sitk.NormalizeImageFilter()\n",
    "rescaleFilter = sitk.RescaleIntensityImageFilter()\n",
    "rescaleFilter.SetOutputMaximum(255)\n",
    "rescaleFilter.SetOutputMinimum(0)\n",
    "\n",
    "image = normalizeFilter.Execute(image)\n",
    "image = rescaleFilter.Execute(image)\n",
    "\n",
    "array = sitk.GetArrayFromImage(image)\n",
    "print(array.shape)\n",
    "\n",
    "image_normalized = sitk.GetImageFromArray(array)\n",
    "\n",
    "sitk.WriteImage(image_normalized, os.path.join(os.getcwd(), \"test2.nii.gz\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 356, 230)\n",
      "(256, 356, 230)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "image = nib.load(b0_images[0])\n",
    "data = image.get_fdata()\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "normalized_vector = data / np.linalg.norm(data)\n",
    "\n",
    "print(normalized_vector.shape)\n",
    "\n",
    "final_img = nib.Nifti1Image(normalized_vector, image.affine)\n",
    "\n",
    "nib.save(final_img, os.path.join(os.getcwd(), \"nibabel.nii\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 356, 230)\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), \"nibabel.nii\")\n",
    "\n",
    "image = nib.load(path)\n",
    "data = image.get_fdata()\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 12, 8, 8, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path_to_residuals = \"/notebooks/tract_residuals/predicted_residuals/epoch_1/image_0.npy\"\n",
    "image0 = np.load(path_to_residuals)\n",
    "print(image0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 178, 115)\n"
     ]
    }
   ],
   "source": [
    "def to_shape(a, shape):\n",
    "    y_, x_, z_ = shape\n",
    "    y, x, z = a.shape\n",
    "    y_pad = (y_-y)\n",
    "    x_pad = (x_-x)\n",
    "    z_pad = (z_-z)\n",
    "    return np.pad(a,((y_pad//2, y_pad//2 + y_pad%2), \n",
    "                     (x_pad//2, x_pad//2 + x_pad%2),\n",
    "                     (z_pad//2, z_pad//2 + z_pad%2)),\n",
    "                  mode = 'constant')\n",
    "\n",
    "# Create random array\n",
    "random_array = np.random.rand(128, 178, 115)\n",
    "print(random_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3]\n",
      "[128, 180, 118]\n",
      "(128, 180, 118)\n"
     ]
    }
   ],
   "source": [
    "# Define kernel size\n",
    "kernel_size = 8 * 2\n",
    "\n",
    "# Get the number of values for each axes that need to be added to fit multiple of kernel\n",
    "padding_needed = [axis % kernel_size for axis in random_array.shape]\n",
    "print(padding_needed)\n",
    "\n",
    "output_shape = []\n",
    "for i in range(random_array.ndim):\n",
    "    output_shape.append(random_array.shape[i] + padding_needed[i])\n",
    "    \n",
    "print(output_shape)\n",
    "\n",
    "# Padding the random array to the new shape\n",
    "random_reshaped = to_shape(random_array, output_shape)\n",
    "print(random_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T23:31:31.335536Z",
     "iopub.status.busy": "2023-07-25T23:31:31.334884Z",
     "iopub.status.idle": "2023-07-25T23:31:31.470032Z",
     "shell.execute_reply": "2023-07-25T23:31:31.469379Z",
     "shell.execute_reply.started": "2023-07-25T23:31:31.335505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 178, 115)\n",
      "(128, 178, 115)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "path = \"/notebooks/model_data_w_resize/dMRI_b0/A10-R01_0028-TT21/DWI_concatenated_b0_resized.nii.gz\"\n",
    "injection_center = \"/notebooks/model_data_w_resize/injection_centers/A10-R01_0028-TT21/inj_center.csv\"\n",
    "stream_path = \"/notebooks/model_data_w_resize/tckmapped_streamlines/A10-R01_0028-TT21/subtracted_unflipped_resized.nii.gz\"\n",
    "\n",
    "# Load the image\n",
    "image = nib.load(path)\n",
    "streamline = nib.load(stream_path)\n",
    "data = image.get_fdata()\n",
    "stream_data = streamline.get_fdata()\n",
    "print(data.shape)\n",
    "print(stream_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T23:33:39.051685Z",
     "iopub.status.busy": "2023-07-25T23:33:39.050902Z",
     "iopub.status.idle": "2023-07-25T23:33:39.153253Z",
     "shell.execute_reply": "2023-07-25T23:33:39.152665Z",
     "shell.execute_reply.started": "2023-07-25T23:33:39.051662Z"
    }
   },
   "outputs": [],
   "source": [
    "b0_hemi = data[64:, :, :]\n",
    "res_hemi = stream_data[64:,:,:]\n",
    "\n",
    "img = nib.Nifti1Image(b0_hemi, affine=np.eye(4))\n",
    "img2 = nib.Nifti1Image(res_hemi, affine=np.eye(4))\n",
    "\n",
    "img_b0 = nib.Nifti1Image(data, affine=np.eye(4))\n",
    "img_str = nib.Nifti1Image(stream_data, affine=np.eye(4))\n",
    "\n",
    "nib.save(img, \"testingcut.nii\")\n",
    "nib.save(img2, \"testingcut_res.nii\")\n",
    "nib.save(img_b0, \"ogb0.nii\")\n",
    "nib.save(img_str, \"ogres.nii\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 178, 115])\n",
      "torch.Size([16, 1, 128, 178, 115])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "random_b0 = torch.rand((16, 1, 128, 178, 115))\n",
    "random_residual = torch.rand((16, 1, 128, 178, 115))\n",
    "\n",
    "print(random_b0.shape)\n",
    "print(random_residual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 32, 32, 32])\n",
      "torch.Size([16, 1, 16, 16, 16])\n",
      "torch.Size([16, 1, 1, 1, 3])\n",
      "torch.Size([16, 1, 1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "from training import *\n",
    "\n",
    "b0_cube = grab_cube_around_voxel(image=random_b0, voxel_coordinates=[5, 5, 5], kernel_size=16)\n",
    "b0_cube = torch.from_numpy(b0_cube).float()\n",
    "\n",
    "res_cube = grab_cube_around_voxel(image=random_residual, voxel_coordinates=[5, 5, 5], kernel_size=8)\n",
    "res_cube = torch.from_numpy(res_cube).float()\n",
    "\n",
    "injection_center = torch.rand((16, 3, 16, 16, 16))\n",
    "image_coordinates = torch.rand((16, 3, 16, 16, 16))\n",
    "\n",
    "print(b0_cube.shape)\n",
    "print(res_cube.shape)\n",
    "print(injection_center.shape)\n",
    "print(image_coordinates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "model = Attention_UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1:  torch.Size([16, 16, 32, 32, 32])\n",
      "maxpool1:  torch.Size([16, 16, 16, 16, 16])\n",
      "conv2:  torch.Size([16, 32, 16, 16, 16])\n",
      "maxpool2:  torch.Size([16, 32, 8, 8, 8])\n",
      "conv3:  torch.Size([16, 64, 8, 8, 8])\n",
      "maxpool3:  torch.Size([16, 64, 4, 4, 4])\n",
      "conv4:  torch.Size([16, 128, 4, 4, 4])\n",
      "maxpool4:  torch.Size([16, 128, 2, 2, 2])\n",
      "center:  torch.Size([16, 256, 2, 2, 2])\n",
      "gating:  torch.Size([16, 256, 2, 2, 2])\n",
      "g_conv4:  torch.Size([16, 128, 4, 4, 4])\n",
      "up4:  torch.Size([16, 128, 4, 4, 4])\n",
      "g_conv3:  torch.Size([16, 64, 8, 8, 8])\n",
      "up3:  torch.Size([16, 64, 8, 8, 8])\n",
      "g_conv2:  torch.Size([16, 32, 16, 16, 16])\n",
      "up2:  torch.Size([16, 32, 16, 16, 16])\n",
      "up1:  torch.Size([16, 16, 32, 32, 32])\n",
      "dsv4:  torch.Size([16, 1, 32, 32, 32])\n",
      "dsv3:  torch.Size([16, 1, 32, 32, 32])\n",
      "dsv2:  torch.Size([16, 1, 32, 32, 32])\n",
      "dsv1:  torch.Size([16, 1, 32, 32, 32])\n",
      "final:  torch.Size([16, 1, 32, 32, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [3, 3, 3, 3, 3], expected input[16, 1, 1, 1, 3] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[39m=\u001b[39m model(b0_cube, injection_center, image_coordinates)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39moutput shape is: \u001b[39m\u001b[39m\"\u001b[39m, output\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/vol/bitbucket/hsa22/miniconda3/envs/diss/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Towards-Standardized-WBM/Marmoset_Residual_Training/models/model_options/attention_unet.py:217\u001b[0m, in \u001b[0;36mAttention_UNet.forward\u001b[0;34m(self, inputs, injection_centers, image_coordinates)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfinal: \u001b[39m\u001b[39m\"\u001b[39m, final\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    216\u001b[0m \u001b[39m# Apply convolutions to injection centers and image coordinates\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m injection_centers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnon_img_model(injection_centers)\n\u001b[1;32m    218\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minjection_centers: \u001b[39m\u001b[39m\"\u001b[39m, injection_centers\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    219\u001b[0m image_coordinates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnon_img_model(image_coordinates)\n",
      "File \u001b[0;32m/vol/bitbucket/hsa22/miniconda3/envs/diss/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/vol/bitbucket/hsa22/miniconda3/envs/diss/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/vol/bitbucket/hsa22/miniconda3/envs/diss/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/vol/bitbucket/hsa22/miniconda3/envs/diss/lib/python3.11/site-packages/torch/nn/modules/conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/vol/bitbucket/hsa22/miniconda3/envs/diss/lib/python3.11/site-packages/torch/nn/modules/conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv3d(\n\u001b[1;32m    598\u001b[0m         F\u001b[39m.\u001b[39mpad(\n\u001b[1;32m    599\u001b[0m             \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[0;32m--> 608\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv3d(\n\u001b[1;32m    609\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups\n\u001b[1;32m    610\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [3, 3, 3, 3, 3], expected input[16, 1, 1, 1, 3] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "output = model(b0_cube, injection_center, image_coordinates)\n",
    "\n",
    "print(\"output shape is: \", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "def glob_files(PATH_NAME, file_format):\n",
    "    INPUT_FILES = []\n",
    "    for file in glob.glob(os.path.join(PATH_NAME, os.path.join(\"**\", \"*.{}\".format(file_format))), recursive=True):\n",
    "        INPUT_FILES.append(file)\n",
    "    return INPUT_FILES\n",
    "\n",
    "nii_gz_files = glob_files(\"/notebooks/model_data_w_resize\", \"nii.gz\")\n",
    "b0_images = [file for file in nii_gz_files if \"b0\" in file and \"resized\" not in file]\n",
    "print(len(b0_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 356, 256)\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "reader = sitk.ImageFileReader()\n",
    "reader.SetFileName(b0_images[0])\n",
    "image = reader.Execute()\n",
    "\n",
    "normalizeFilter = sitk.NormalizeImageFilter()\n",
    "rescaleFilter = sitk.RescaleIntensityImageFilter()\n",
    "rescaleFilter.SetOutputMaximum(255)\n",
    "rescaleFilter.SetOutputMinimum(0)\n",
    "\n",
    "image = normalizeFilter.Execute(image)\n",
    "image = rescaleFilter.Execute(image)\n",
    "\n",
    "array = sitk.GetArrayFromImage(image)\n",
    "print(array.shape)\n",
    "\n",
    "image_normalized = sitk.GetImageFromArray(array)\n",
    "\n",
    "sitk.WriteImage(image_normalized, os.path.join(os.getcwd(), \"test2.nii.gz\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 356, 230)\n",
      "(256, 356, 230)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "image = nib.load(b0_images[0])\n",
    "data = image.get_fdata()\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "normalized_vector = data / np.linalg.norm(data)\n",
    "\n",
    "print(normalized_vector.shape)\n",
    "\n",
    "final_img = nib.Nifti1Image(normalized_vector, image.affine)\n",
    "\n",
    "nib.save(final_img, os.path.join(os.getcwd(), \"nibabel.nii\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 356, 230)\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), \"nibabel.nii\")\n",
    "\n",
    "image = nib.load(path)\n",
    "data = image.get_fdata()\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 12, 8, 8, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path_to_residuals = \"/notebooks/tract_residuals/predicted_residuals/epoch_1/image_0.npy\"\n",
    "image0 = np.load(path_to_residuals)\n",
    "print(image0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 178, 115)\n"
     ]
    }
   ],
   "source": [
    "def to_shape(a, shape):\n",
    "    y_, x_, z_ = shape\n",
    "    y, x, z = a.shape\n",
    "    y_pad = (y_-y)\n",
    "    x_pad = (x_-x)\n",
    "    z_pad = (z_-z)\n",
    "    return np.pad(a,((y_pad//2, y_pad//2 + y_pad%2), \n",
    "                     (x_pad//2, x_pad//2 + x_pad%2),\n",
    "                     (z_pad//2, z_pad//2 + z_pad%2)),\n",
    "                  mode = 'constant')\n",
    "\n",
    "# Create random array\n",
    "random_array = np.random.rand(128, 178, 115)\n",
    "print(random_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3]\n",
      "[128, 180, 118]\n",
      "(128, 180, 118)\n"
     ]
    }
   ],
   "source": [
    "# Define kernel size\n",
    "kernel_size = 8 * 2\n",
    "\n",
    "# Get the number of values for each axes that need to be added to fit multiple of kernel\n",
    "padding_needed = [axis % kernel_size for axis in random_array.shape]\n",
    "print(padding_needed)\n",
    "\n",
    "output_shape = []\n",
    "for i in range(random_array.ndim):\n",
    "    output_shape.append(random_array.shape[i] + padding_needed[i])\n",
    "    \n",
    "print(output_shape)\n",
    "\n",
    "# Padding the random array to the new shape\n",
    "random_reshaped = to_shape(random_array, output_shape)\n",
    "print(random_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T23:31:31.335536Z",
     "iopub.status.busy": "2023-07-25T23:31:31.334884Z",
     "iopub.status.idle": "2023-07-25T23:31:31.470032Z",
     "shell.execute_reply": "2023-07-25T23:31:31.469379Z",
     "shell.execute_reply.started": "2023-07-25T23:31:31.335505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 178, 115)\n",
      "(128, 178, 115)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "path = \"/notebooks/model_data_w_resize/dMRI_b0/A10-R01_0028-TT21/DWI_concatenated_b0_resized.nii.gz\"\n",
    "injection_center = \"/notebooks/model_data_w_resize/injection_centers/A10-R01_0028-TT21/inj_center.csv\"\n",
    "stream_path = \"/notebooks/model_data_w_resize/tckmapped_streamlines/A10-R01_0028-TT21/subtracted_unflipped_resized.nii.gz\"\n",
    "\n",
    "# Load the image\n",
    "image = nib.load(path)\n",
    "streamline = nib.load(stream_path)\n",
    "data = image.get_fdata()\n",
    "stream_data = streamline.get_fdata()\n",
    "print(data.shape)\n",
    "print(stream_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T23:33:39.051685Z",
     "iopub.status.busy": "2023-07-25T23:33:39.050902Z",
     "iopub.status.idle": "2023-07-25T23:33:39.153253Z",
     "shell.execute_reply": "2023-07-25T23:33:39.152665Z",
     "shell.execute_reply.started": "2023-07-25T23:33:39.051662Z"
    }
   },
   "outputs": [],
   "source": [
    "b0_hemi = data[64:, :, :]\n",
    "res_hemi = stream_data[64:,:,:]\n",
    "\n",
    "img = nib.Nifti1Image(b0_hemi, affine=np.eye(4))\n",
    "img2 = nib.Nifti1Image(res_hemi, affine=np.eye(4))\n",
    "\n",
    "img_b0 = nib.Nifti1Image(data, affine=np.eye(4))\n",
    "img_str = nib.Nifti1Image(stream_data, affine=np.eye(4))\n",
    "\n",
    "nib.save(img, \"testingcut.nii\")\n",
    "nib.save(img2, \"testingcut_res.nii\")\n",
    "nib.save(img_b0, \"ogb0.nii\")\n",
    "nib.save(img_str, \"ogres.nii\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

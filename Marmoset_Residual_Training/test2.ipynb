{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from models import *\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hpc = False\n",
    "labs = False\n",
    "paperspace = True\n",
    "\n",
    "if hpc:\n",
    "    main_data_path = \"/rds/general/user/hsa22/ephemeral/Brain_MINDS/model_data\"\n",
    "    main_logs_path = \"/rds/general/user/hsa22/ephemeral/Brain_MINDS/tract_residuals\"\n",
    "elif labs:\n",
    "    main_data_path = \"/media/hsa22/Expansion/Brain_MINDS/model_data\"\n",
    "    main_logs_path = \"/media/hsa22/Expansion//Brain_MINDS/tract_residuals\"\n",
    "elif paperspace:\n",
    "    main_data_path = \"/notebooks/model_data_w_resize\"\n",
    "    main_logs_path = \"/notebooks/tract_residuals\"\n",
    "else:\n",
    "    main_data_path = \"D:\\\\Brain-MINDS\\\\model_data\"\n",
    "    main_logs_path = \"D:\\\\Brain-MINDS\\\\tract_residuals\"\n",
    "\n",
    "residual_arrays_path = os.path.join(main_logs_path, \"predicted_residuals\")\n",
    "training_log_path = os.path.join(main_logs_path, \"training_logs\", \"resnet_log.csv\")\n",
    "model_filename = os.path.join(main_logs_path, \"models\", \"resnet_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the configs dictionary\n",
    "configs = {\n",
    "\n",
    "    ####### Model #######\n",
    "    \"model_name\" : \"resnet\", # Model name\n",
    "    \"input_nc\" : 1, # Number of input channels\n",
    "    \"output_nc\" : 3, # Number of output channels\n",
    "    \"ngf\" : 64, # Number of filters in first conv layer\n",
    "    \"num_blocks\" : 6, # Number of residual blocks\n",
    "    \"norm_layer\" : \"BatchNorm3d\", # Normalization layer\n",
    "    \"use_dropout\" : False, # Dropout layers\n",
    "    \"padding_type\" : \"reflect\", # Padding type\n",
    "    \n",
    "    ####### Training #######\n",
    "    \"n_epochs\" : 100, # Number of epochs\n",
    "    \"loss\" : \"mse_loss\", # Loss function\n",
    "    \"optimizer\" : \"Adam\", # Optimizer\n",
    "    \"evaluation_metric\" : \"MSE_loss\", # Evaluation metric\n",
    "    \"save_best\" : True, # Save best model\n",
    "    \"regularized\" : False, # Regularization\n",
    "    \"vae\" : False, # Variational autoencoder\n",
    "\n",
    "    ####### Data #######\n",
    "    \"main_data_path\" : main_data_path, # Data path\n",
    "    \"training_log_path\" : training_log_path, # Training log path\n",
    "    \"model_filename\" : model_filename, # Model filename\n",
    "    \"residual_arrays_path\" : residual_arrays_path, # Path to the residuals array\n",
    "    \"batch_size\" : 1, # Batch size\n",
    "    \"validation_batch_size\" : 1, # Validation batch size\n",
    "    \n",
    "    ####### Parameters #######\n",
    "    \"initial_learning_rate\" : 1e-04, # Initial learning rate\n",
    "    \"early_stopping_patience\": 50, # Early stopping patience\n",
    "    \"decay_patience\": 20, # Learning rate decay patience\n",
    "    \"decay_factor\": 0.5, # Learning rate decay factor\n",
    "    \"min_learning_rate\": 1e-08, # Minimum learning rate\n",
    "    \"save_last_n_models\": 10, # Save last n models\n",
    "\n",
    "    ####### Misc #######\n",
    "    \"skip_val\" : True, # Skip validation\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration path and save it as a .json file\n",
    "config_path = os.path.join(\"configs\", configs[\"model_name\"] + \".json\")\n",
    "\n",
    "# Save the configuration\n",
    "dump_json(configs, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is: ResnetEncoder\n",
      "Metric to monitor is: train_loss\n",
      "Criterion is: <function mse_loss at 0x7f2688ce4dc0>\n",
      "Optimizer is: Adam\n",
      "Metric to monitor is:  train_loss\n",
      "Residual arrays path is:  /notebooks/tract_residuals/predicted_residuals\n",
      "Number of x_centers: (4,)\n",
      "Number of y_centers: (12,)\n",
      "Number of z_centers: (8,)\n",
      "Current x coordinate: 0\n",
      "Epoch [2][  0/104]\tTime  8.464 ( 8.464)\tData  0.285 ( 0.285)\tLoss 2.9623e-02 (3.0404e-02)\n",
      "Current x coordinate: 16\n",
      "Epoch [2][  0/104]\tTime  5.498 ( 6.981)\tData  0.285 ( 0.285)\tLoss 3.9087e+00 (2.3380e+16)\n",
      "Current x coordinate: 32\n",
      "Epoch [2][  0/104]\tTime  5.625 ( 6.529)\tData  0.285 ( 0.285)\tLoss 3.6293e+01 (1.4584e+17)\n",
      "Current x coordinate: 48\n",
      "Epoch [2][  0/104]\tTime  5.620 ( 6.302)\tData  0.285 ( 0.285)\tLoss 1.0051e+02 (1.9611e+17)\n",
      "Number of x_centers: (4,)\n",
      "Number of y_centers: (12,)\n",
      "Number of z_centers: (8,)\n",
      "Current x coordinate: 0\n",
      "Epoch [2][  1/104]\tTime  5.563 ( 6.154)\tData  0.002 ( 0.144)\tLoss 1.1077e+02 (1.6024e+17)\n",
      "Current x coordinate: 16\n",
      "Epoch [2][  1/104]\tTime  5.529 ( 6.050)\tData  0.002 ( 0.144)\tLoss 1.4056e+02 (1.9136e+17)\n",
      "Current x coordinate: 32\n",
      "Epoch [2][  1/104]\tTime  5.616 ( 5.988)\tData  0.002 ( 0.144)\tLoss 2.1142e+02 (2.1984e+17)\n",
      "Current x coordinate: 48\n",
      "Epoch [2][  1/104]\tTime  5.677 ( 5.949)\tData  0.002 ( 0.144)\tLoss 3.4341e+02 (1.9821e+17)\n",
      "Number of x_centers: (4,)\n",
      "Number of y_centers: (12,)\n",
      "Number of z_centers: (8,)\n",
      "Current x coordinate: 0\n",
      "Epoch [2][  2/104]\tTime  5.698 ( 5.921)\tData  0.002 ( 0.097)\tLoss 3.6898e+02 (1.7618e+17)\n",
      "Current x coordinate: 16\n",
      "Epoch [2][  2/104]\tTime  5.661 ( 5.895)\tData  0.002 ( 0.097)\tLoss 3.2717e+02 (1.7266e+17)\n",
      "Current x coordinate: 32\n",
      "Epoch [2][  2/104]\tTime  5.698 ( 5.877)\tData  0.002 ( 0.097)\tLoss 4.3338e+02 (2.1344e+17)\n",
      "Current x coordinate: 48\n",
      "Epoch [2][  2/104]\tTime  5.691 ( 5.862)\tData  0.002 ( 0.097)\tLoss 6.7936e+02 (2.4255e+17)\n",
      "Number of x_centers: (4,)\n",
      "Number of y_centers: (12,)\n",
      "Number of z_centers: (8,)\n",
      "Current x coordinate: 0\n",
      "Epoch [2][  3/104]\tTime  5.624 ( 5.843)\tData  0.003 ( 0.073)\tLoss 6.8384e+02 (2.6647e+17)\n",
      "Current x coordinate: 16\n",
      "Epoch [2][  3/104]\tTime  5.765 ( 5.838)\tData  0.003 ( 0.073)\tLoss 1.1103e+03 (2.8763e+17)\n",
      "Current x coordinate: 32\n",
      "Epoch [2][  3/104]\tTime  5.545 ( 5.818)\tData  0.003 ( 0.073)\tLoss 1.4552e+03 (3.0987e+17)\n",
      "Current x coordinate: 48\n",
      "Epoch [2][  3/104]\tTime  5.548 ( 5.801)\tData  0.003 ( 0.073)\tLoss 1.7845e+03 (2.9931e+17)\n",
      "Number of x_centers: (4,)\n",
      "Number of y_centers: (12,)\n",
      "Number of z_centers: (8,)\n",
      "Current x coordinate: 0\n",
      "Epoch [2][  4/104]\tTime  5.475 ( 5.782)\tData  0.003 ( 0.059)\tLoss 1.8025e+03 (2.8171e+17)\n",
      "Current x coordinate: 16\n",
      "Epoch [2][  4/104]\tTime  5.489 ( 5.766)\tData  0.003 ( 0.059)\tLoss 1.6143e+03 (3.1667e+17)\n",
      "Current x coordinate: 32\n",
      "Epoch [2][  4/104]\tTime  5.572 ( 5.756)\tData  0.003 ( 0.059)\tLoss 2.1870e+03 (3.8432e+17)\n",
      "Current x coordinate: 48\n",
      "Epoch [2][  4/104]\tTime  5.509 ( 5.743)\tData  0.003 ( 0.059)\tLoss 3.2274e+03 (4.3860e+17)\n",
      "Number of x_centers: (4,)\n",
      "Number of y_centers: (12,)\n",
      "Number of z_centers: (8,)\n",
      "Current x coordinate: 0\n",
      "Epoch [2][  5/104]\tTime  5.518 ( 5.733)\tData  0.002 ( 0.050)\tLoss 3.3230e+03 (4.6792e+17)\n",
      "Current x coordinate: 16\n"
     ]
    }
   ],
   "source": [
    "# Load the configuration\n",
    "configs = load_json(config_path)\n",
    "\n",
    "# Define the metric to monitor based on whether we're skipping val or not\n",
    "if configs[\"skip_val\"]:\n",
    "    metric_to_monitor = \"train_loss\"\n",
    "else:\n",
    "    metric_to_monitor = \"val_loss\"\n",
    "\n",
    "# Define the groups\n",
    "if configs[\"skip_val\"]:\n",
    "    groups = (\"training\",)\n",
    "else:\n",
    "    groups = (\"training\", \"validation\")\n",
    "\n",
    "model_metrics = (configs[\"evaluation_metric\"],)\n",
    "\n",
    "run_pytorch_training(configs, configs[\"model_filename\"], configs[\"training_log_path\"],\n",
    "                     configs[\"residual_arrays_path\"],\n",
    "                     metric_to_monitor=metric_to_monitor,\n",
    "                     bias=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
